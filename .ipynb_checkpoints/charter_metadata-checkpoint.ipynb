{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RADARSAT-2 Charter Images\n",
    "*Taken from documents:*\n",
    "\n",
    "* **Packaging RADARSAT Acquisitions for the Charter.docx**\n",
    "* **COS2_CSA_ICD.doc**\n",
    "* **PR0541_A_COS-2_MPP_Manual_of_Operations.pdf**\n",
    "\n",
    ">>> **Note**: The method used to create the metadata XML in this notebook has been replaced by using the ACP of the acquisitions instead. As I did not have the time to update it, it is included for documentation purposes nonetheless. The finished script and README based on this notebook currently resides in:\n",
    "\n",
    ">>>`W:\\Radarsat\\PLANNERS\\CHARTER\\Product Metadata`\n",
    "\n",
    "As a part of the International Charter, Space and Major Disasters’ tools, the [Charter’s website](https://www.disasterscharter.org/web/guest/home) offers to the scientific community and general public an access to the images captured and metadata in the course of the activations. This is done through an interface called CGT ([Charter Geographic Tool](http://cgt.prod.esaportal.eu/charterng/#wmdr53ctcr1j:7)) which allows access to this information.\n",
    "\n",
    "<img title=\"Charter Website\" src=\"img/charter-website.png\" width=\"600\">\n",
    "\n",
    "As one of the Charter’s members, the **CSA must populate this database** whenever we provide acquisitions in response to the requests we receive. This includes thumbnail- and quicklook-sized versions of the imagery we acquire, and needs to be submitted independently by the Agency. The Charter Operating System (COS2) has provided a means to programatically upload that data onto the site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirements\n",
    "Charter users need to upload two sets of data:\n",
    "\n",
    ">Charter agencies’ can make:\n",
    ">1. Their satellite Acquisition and Archive Plan (**AAP**) and \n",
    ">2. **Metadata/data products**\n",
    ">available for specific Charter activations. Their upload in the COS-2 system can be made either through the web interface or through a *cURL* command line.\n",
    "\n",
    "### a) AAP file (csv)\n",
    "The AAP is a single `.csv` that represents details regarding the acquisitions taken by CSA for that Charter call.\n",
    "\n",
    "#### Format\n",
    ">`AGENCY,SATELLITE,SENSOR,MODE,ACQUISITION_DATE,ARCHIVE_OR_PROGRAM`\n",
    "\n",
    ">`<AAAA>, <SSSSS>, <SESESESE>, <MMMM>, < dd MMMMM yyyy>, <PPPPPPPP>`\n",
    "\n",
    "#### Submission\n",
    "It can be sent to the COS-2 API my making a command-line call with cURL. For example, the following line submits the AAP to the COS-2 test server:\n",
    "~~~bash\n",
    "curl -i -k -X POST -H \"Content-Type: multipart/form-data\" --form ESA-<call-id>-AAP.csv=\"@<aap-file-path>\" --basic https://<username>:<password>@disasterscharter.org/charterportlets/service/app/esa/<call-id>\n",
    "~~~\n",
    "\n",
    "### b) Metadata / data products (zip)\n",
    "Contains extra information that depends on the satellite/instrument.\n",
    "\n",
    "#### Contents\n",
    "In section 4.4,\n",
    ">Data product shall be submitted in a zip file. The flat zip file (i.e. the zip file shall not contain any folder structure) shall include:\n",
    "\n",
    ">•\tThe metadata file (see format in section 4.2 and 4.3, file with fixed name `EOP.XML`)\n",
    "\n",
    ">•\tThe thumbnail: optional (JPEG file with fixed name `ICON.JPG`), max 200 pixels wide\n",
    "\n",
    ">•\tThe quicklook: mandatory (JPEG file with fixed name `PREVIEW.JPG`), max size 2 MB\n",
    "\n",
    ">•\tThe product: optional (.PNG, .JPG, .TIF, .XML, .TXT, .DIM with name `PRODUCT.<extension>`)\n",
    "\n",
    "In CSA's case, the actual image product can only be delivered directly to the Point of Contacts, so we only need to package the first three items in that list.\n",
    "\n",
    "#### Submission\n",
    "This one can be sent to COS-2 with the following command, also to the test server:\n",
    "~~~bash\n",
    "curl -i -k -X POST --form product=\"@<product-file-path>\" --form publicdata=false --basic https://<username>:<password>@disasterscharter.org /charterportlets/service/data-product/<agency>/<satellite>/<call-id>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate AAPs\n",
    "For each activation, a single `.csv` file that contains summary info regarding the acquisitions needs to be generated. Written by past student Joshua Chan-Fee, they are generated directly inside SatOps' Charter Database (MS Access), found at: \n",
    "\n",
    "    W:\\Satellite Operations\\Data Management\\Charter Activations.accdb\n",
    "\n",
    "Unfortunately, I do not have access to the aforementioned folder at the moment, and I can't comment on it further.\n",
    "\n",
    "The general rule applies however:\n",
    "\n",
    "* Generate the appropriate `.csv` file for each activation in `Charter_Activations.accdb`\n",
    "    - Making sure they are named  `$ACTIVATION_AAP.csv`, where `$ACTIVATION` is the activation number, e.g. `511_AAP.csv`.\n",
    "    \n",
    "We will be uploading them later, at [Section 6](#6.-Upload-to-COS-2-API) of this Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate metadata / data products\n",
    "In this case, the metadata and data products are generated from files found inside the `.zip` archives of the actual data products. These files usually \"weigh\" multiple hundreds of MB, sometimes `<` 2GB. All we need, however, is three small files packaged alongside the satellite image:\n",
    "\n",
    "* `product.xml` for the image metadata, \n",
    "* `product.kml` for the frame's geographical coordinates, and\n",
    "* `BrowseImage.tif`, to generate the thumbnail and QuickLook images.\n",
    "\n",
    "They unfortunately can't be accessed without downloading the whole `.zip`.\n",
    "\n",
    "`(TO CONSIDER)` *This might be able to get all done without downloading the actual image file, but using the APT's archive files, submitted ACPs, as well as Quicklook images straight from NEODF website.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are defined in COS-2 API standards.\n",
    "xml_filename = 'EOP.xml'\n",
    "thumbnail_filename = 'ICON.JPG'\n",
    "quicklook_filename = 'PREVIEW.JPG'\n",
    "\n",
    "# Our test image is taken from Charter Activation #614\n",
    "activation_number = '613'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Metadata XML\n",
    "The file `EOP.xml` can be populated from the metadata found in each product, in a file called `product.xml`.\n",
    "\n",
    "|Variable name                                                                                                       |  Example  |\n",
    "|--------------------------------------------------------------------------------------------------------------------|-----------|\n",
    "|`<eop:parentIdentifier>`                                                                                            |`urn:ogc:def:EOP:CSA:RSAT1`|\n",
    "|`<eop:status>`                                                                                                      |`ARCHIVED`\n",
    "|`<gml:TimePeriod><gml:beginPosition>`                                                                               |`2008-09-02T11:59:12.145Z`\n",
    "|`<gml:TimePeriod><gml:endPosition>`                                                                                 |`2008-09-02T11:59:12.145Z`\n",
    "|`<eop:Platform><eop:shortName>`                                                                                     |`RADARSAT1`|\n",
    "|`<eop:Instrument><eop:shortName>`                                                                                   |`SAR_RAD_1`|\n",
    "|`<eop:Sensor><eop:OperationalMode>`                                                                                 |`FINE`|\n",
    "|`<gml:Polygon><gml:exterior><gml:LinearRing>`   `<gml:posList>`                                                     |`30.52302 -90.27364 30.36339 -89.19232 28.97988 -89.47291 29.14067 -90.53881 30.52302 -90.27364`\n",
    "|`<eop:browse><eop:BrowseInformation>`   `<eop:type>`                                                                |`THUMBNAIL`|\n",
    "|`<eop:referenceSystemIdentifier   codeSpace=\"EPSG\">`EPSG:4326`</eop:referenceSystemIdentifier>`   `<eop:fileName>`  |`ICON.JPG`|\n",
    "|`<eop:BrowseInformation><eop:type>`                                                                                 |`QUICKLOOK`|\n",
    "|`<eop:referenceSystemIdentifier   codeSpace=\"EPSG\">`EPSG:4326`</eop:referenceSystemIdentifier>`     `<eop:fileName>`|`PREVIEW.JPG`|\n",
    "\n",
    "Further details and lists of valid values are found in the COS-2 documentation (`COS-CSA-ICD.doc`), \n",
    "\n",
    "All these attributes can be taken directly by parsing `product.xml`, for the exception of `<eop:status>`, which can be inferred by the difference between acquisition and processing dates:\n",
    "\n",
    "~~~xml\n",
    "<sourceAttributes>\n",
    "    <rawDataStartTime>2009-12-01T09:04:42.605591Z</rawDataStartTime>\n",
    "~~~\n",
    "\n",
    "vs.\n",
    "\n",
    "~~~xml\n",
    "<imageGenerationParameters>\n",
    "    <generalProcessingInformation>\n",
    "        <processingTime>2017-06-08T13:53:41.000000Z</processingTime>\n",
    "~~~\n",
    "\n",
    "is clearly an archive image, as it was processed almost 8 years after its original acquisition.\n",
    "\n",
    "#### Parsing\n",
    "We start by using the Python package **BeautifulSoup** to parse and easily access the XML file's contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<satellite>RADARSAT-2</satellite>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "product_file = '../data/charter/product.xml'  # Hardcoded value for this NB\n",
    "product_kml = '../data/charter/product.kml'\n",
    "\n",
    "with open(product_file) as f:\n",
    "    xml_soup = BeautifulSoup(f, 'xml')\n",
    "print(xml_soup.satellite)\n",
    "with open(product_kml) as k:\n",
    "    kml_soup = BeautifulSoup(k, 'xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to construct a lookup table, so that we can map the COS-2 variables to the contents of the `product.xml` tags. We'll restrict it to RADARSAT-2 images only for now, as R1 imagery hasn't been used in Charter calls for over 7 years now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to translate MDA's beam mode names into the appropriate COS-2 names (capitalization, etc.), which we'll do with a dictionary. Unfortunately, these do not contain the list of beam types added after R2's launch, so we'll go with the closest thing (arbitrarily decided) there is in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MULTI_LOOK_FINE'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_modes = {\n",
    "    'Fine' : 'FINE',\n",
    "    'Standard' : 'STANDARD',\n",
    "    'Wide' : 'WIDE',\n",
    "    'ScanSAR Narrow' : 'SCANSAR_NARROW',\n",
    "    'ScanSAR Wide' : 'SCANSAR_WIDE',\n",
    "    'Wide Fine' : 'WIDE_FINE',\n",
    "    'Multi-Look Fine' : 'MULTI_LOOK_FINE',\n",
    "    'Wide Multi-Look Fine': 'WIDE_MULTI_LOOK_FINE',\n",
    "    'Ultrafine' : 'ULTRA_FINE',\n",
    "    'Wide Ultrafine' : 'WIDE_ULTRA_FINE',\n",
    "    'Spotlight A' : 'SPOTLIGHT',\n",
    "    # Map these to others as they're not part of the COS-2 list\n",
    "    'Wide Fine Quad Polarization' : 'WIDE_FINE',\n",
    "    'Fine Quad Polarization' : 'FINE',\n",
    "    'Wide Standard Quad Polarization' : 'WIDE',\n",
    "    'Standard Quad Polarization' : 'STANDARD',\n",
    "    'Extra Fine' : 'WIDE_FINE',\n",
    "    'High Incidence' : 'STANDARD',\n",
    "    'Low Incidence' : 'WIDE',\n",
    "    }\n",
    "beam_modes.get('Multi-Look Fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.163425407653519e+01,2.218400413421320e+01 9.203466737934289e+01,2.211598181214218e+01 9.210855095868085e+01,2.248919246063661e+01 9.170701249599688e+01,2.255699246458139e+01 9.163425407653519e+01,2.218400413421320e+01\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def ISO_to_utc(string):\n",
    "    \"\"\"Given a string representing ISO 8601 time,\n",
    "    returns datetime object.\n",
    "    \n",
    "    str -> datetime\"\"\"\n",
    "    pattern = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "    return datetime.datetime.strptime(string, pattern)\n",
    "    \n",
    "def compare(start_time, end_time):\n",
    "    \"\"\"Compares the `rawDataStartTime` to the `processingTime`\n",
    "    from a `product.xml` file, returns either 'ARCHIVED' or\n",
    "    'PROGRAMMED'. Arbitrary cutoff date is 3 days.\n",
    "    \n",
    "    dt, dt -> str\n",
    "    \"\"\"\n",
    "    days = 3\n",
    "    duration = (end_time - start_time).seconds\n",
    "    if duration > days * 86400:\n",
    "        return 'ARCHIVED'\n",
    "    return 'PROGRAMMED'\n",
    "\n",
    "image_id = xml_soup.imageId.string\n",
    "start_time = ISO_to_utc(xml_soup.rawDataStartTime.string)\n",
    "end_time = ISO_to_utc(xml_soup.zeroDopplerTimeLastLine.string)\n",
    "processing_time = ISO_to_utc(xml_soup.processingTime.string)\n",
    "status = compare(start_time, processing_time)\n",
    "beam_mode = beam_modes.get(xml_soup.acquisitionType.string)\n",
    "\n",
    "# The following encodes digits as '9.163425407653519e+01', might be problematic\n",
    "region = kml_soup.LinearRing.coordinates.string\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing the XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 23))\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'status' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4568cee2711c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0meop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mBrowseInformation\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0meop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbrowse\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m </sar:EarthObservation>\"\"\".format(status, utc_to_ISO(start_time), utc_to_ISO(end_time), beam_mode, region)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'status' is not defined"
     ]
    }
   ],
   "source": [
    "def utc_to_ISO(dt):\n",
    "    \"\"\"Given a datetime object, formats it\n",
    "    and returns ISO 8601 time string.\n",
    "    \n",
    "    datetime -> str\"\"\"\n",
    "    pattern = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "    return dt.strftime(pattern)\n",
    "    \n",
    "string = \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
    "<sar:EarthObservation xmlns:eop=\"http://earth.esa.int/eop\" xmlns:gml=\"http://www.opengis.net/gml\" xmlns:sar=\"http://earth.esa.int/sar\" version=\"1.2.2\">\n",
    "  <gml:metaDataProperty>\n",
    "    <eop:EarthObservationMetaData>\n",
    "      <eop:identifier>SAR123</eop:identifier>\n",
    "      <eop:parentIdentifier>urn:ogc:def:EOP:CSA:RSAT2</eop:parentIdentifier>\n",
    "      <eop:productType/>\n",
    "      <eop:status>{0}</eop:status>\n",
    "    </eop:EarthObservationMetaData>\n",
    "  </gml:metaDataProperty>\n",
    "  <gml:validTime>\n",
    "    <gml:TimePeriod>\n",
    "      <gml:beginPosition>{1}</gml:beginPosition>\n",
    "      <gml:endPosition>{2}</gml:endPosition>\n",
    "    </gml:TimePeriod>\n",
    "  </gml:validTime>\n",
    "  <gml:using>\n",
    "    <eop:EarthObservationEquipment>\n",
    "      <eop:platform>\n",
    "        <eop:Platform>\n",
    "          <eop:shortName>RADARSAT2</eop:shortName>\n",
    "        </eop:Platform>\n",
    "      </eop:platform>\n",
    "      <eop:instrument>\n",
    "        <eop:Instrument>\n",
    "          <eop:shortName>SAR_RAD_2</eop:shortName>\n",
    "        </eop:Instrument>\n",
    "      </eop:instrument>\n",
    "      <eop:sensor>\n",
    "        <eop:Sensor>\n",
    "          <eop:sensorType>RADAR</eop:sensorType>\n",
    "          <eop:operationalMode>{3}</eop:operationalMode>\n",
    "        </eop:Sensor>\n",
    "      </eop:sensor>\n",
    "    </eop:EarthObservationEquipment>\n",
    "  </gml:using>\n",
    "  <gml:target>\n",
    "    <eop:Footprint>\n",
    "      <gml:multiExtentOf>\n",
    "        <gml:MultiSurface srsName=\"EPSG:4326\">\n",
    "          <gml:surfaceMembers>\n",
    "            <gml:Polygon>\n",
    "              <gml:exterior>\n",
    "                <gml:LinearRing>\n",
    "                  <gml:posList>{4}</gml:posList>\n",
    "                </gml:LinearRing>\n",
    "              </gml:exterior>\n",
    "            </gml:Polygon>\n",
    "          </gml:surfaceMembers>\n",
    "        </gml:MultiSurface>\n",
    "      </gml:multiExtentOf>\n",
    "    </eop:Footprint>\n",
    "  </gml:target>\n",
    "  <eop:browse>\n",
    "    <eop:BrowseInformation>\n",
    "      <eop:type>THUMBNAIL</eop:type>\n",
    "      <eop:referenceSystemIdentifier codeSpace=\"EPSG\">EPSG:4326</eop:referenceSystemIdentifier>\n",
    "      <eop:fileName>ICON.JPG</eop:fileName>\n",
    "    </eop:BrowseInformation>\n",
    "  </eop:browse>\n",
    "  <eop:browse>\n",
    "    <eop:BrowseInformation>\n",
    "      <eop:type>QUICKLOOK</eop:type>\n",
    "      <eop:referenceSystemIdentifier codeSpace=\"EPSG\">EPSG:4326</eop:referenceSystemIdentifier>\n",
    "      <eop:fileName>PREVIEW.JPG</eop:fileName>\n",
    "    </eop:BrowseInformation>\n",
    "  </eop:browse>\n",
    "</sar:EarthObservation>\"\"\".format(status, utc_to_ISO(start_time), utc_to_ISO(end_time), beam_mode, region)\n",
    "\n",
    "with open(xml_filename, 'w') as f:\n",
    "    f.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Create imagery thumbnails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the image\n",
    "Apart from the (possibly multiple) satellite image(s) found in the zip file, there is also a 512-pixel wide QuickLook, `BrowseImage.tif`. As it is ~256kB (i.e. far less than 2MB), we can use it directly as the Quicklook image, and we'll resize it to generate the thumbnail (`<`200 px). \n",
    "\n",
    "To do this we'll use the Python package called **Pillow**. Its history is diverse as it is a fork and drop-in replacement of the now-unmaintained PIL (Python Imaging Library), and for that reason is imported as such in Python code. It is pre-installed in the Anaconda distribution, but can be installed with `pip install Pillow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "\n",
    "file = '../data/charter/BrowseImage.tif'\n",
    "\n",
    "raster = Image.open(file)\n",
    "print('Image size:', raster.size, 'pixels')\n",
    "print('Image file size: ', round(os.path.getsize(file) / 1024, 2), 'kB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what we're working with. We'll plot this with the Jupyter Notebook `%matplotlib notebook` inline \"magic\", which loads **matplotlib** with interactive plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Make sure sizing is right\n",
    "plt.figure(figsize=(5.12, 5.12), dpi=100)\n",
    "plt.title('Original Image (512x512 px)')\n",
    "plt.imshow(np.asarray(raster), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying auto-contrast and resize\n",
    "GDAL has loaded a pure numpy array from the TIF, so all we need to do is to apply a linear function (as in [linear map](https://en.wikipedia.org/wiki/Linear_map)) that boosts the contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def resize_and_contrast(file_in, file_out, resize=None):\n",
    "    \"\"\"Given input and output filenames, and `resize` in pixels,\n",
    "    resizes and auto-contrasts the `file_in` image and saves\n",
    "    it as `file_out`.\n",
    "    \n",
    "    Args:\n",
    "        file_in: Filename of the image to be converted\n",
    "        file_out: Output filename\n",
    "        resize: Output size of the image (px), default=512 px\n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    str, str, int -> None\"\"\"\n",
    "    try:\n",
    "        # Make a tuple out of the pixel size\n",
    "        size = (resize, resize)\n",
    "        \n",
    "        image = Image.open(file_in)\n",
    "        # Apply some blur to slightly smooth out pixels\n",
    "        image = image.filter(ImageFilter.GaussianBlur(radius=0.5))\n",
    "        # Apply some more contrast\n",
    "        contrast = ImageEnhance.Contrast(image)\n",
    "        image = contrast.enhance(1.5)\n",
    "        \n",
    "        if resize:\n",
    "            # Resize the image to `size`\n",
    "            image.thumbnail(size, resample=Image.BICUBIC)\n",
    "            # More blur\n",
    "            image = image.filter(ImageFilter.GaussianBlur(radius=0.5))\n",
    "        image.save(file_out, format=None)\n",
    "    except IOError:\n",
    "        print('Cannot resize', file_in, 'to', file_out)\n",
    "        \n",
    "resize_and_contrast(file, quicklook_filename)  # Only apply contrast\n",
    "resize_and_contrast(file, thumbnail_filename, resize=100)\n",
    "\n",
    "# See what the thumbnail looks like\n",
    "thumbnail = Image.open(thumbnail_filename, 'r')\n",
    "plt.figure(figsize=(1, 1), dpi=100)\n",
    "plt.title('Thumbnail (100x100 px)')\n",
    "plt.imshow(np.asarray(thumbnail), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See what the quicklook looks like\n",
    "quicklook = Image.open(quicklook_filename, 'r')\n",
    "plt.figure(figsize=(5.12, 5.12), dpi=100)\n",
    "plt.title('Processed Quicklook (512x512 px)')\n",
    "plt.imshow(np.asarray(quicklook), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Packaging the metadata / data products\n",
    "Now we just need to package the two resized images and the XML file in one zip file, and we're good to go. As per the docs:\n",
    "\n",
    ">Data product shall be submitted in a zip file. The flat zip file (i.e. the zip file shall not contain any folder structure) shall include:\n",
    "\n",
    ">•\tThe metadata file (see format in section 4.2 and 4.3, file with fixed name `EOP.XML`)\n",
    "\n",
    ">•\tThe thumbnail: optional (JPEG file with fixed name `ICON.JPG`), max 200 pixels wide\n",
    "\n",
    ">•\tThe quicklook: mandatory (JPEG file with fixed name `PREVIEW.JPG`), max size 2 MB\n",
    "\n",
    "\n",
    ">•\tThe product: optional (.PNG, .JPG, .TIF, .XML, .TXT, .DIM with name `PRODUCT.<extension>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Get the zipfile name correct\n",
    "zip_filename = activation_number + '_RADARSAT2_' + image_id + '.zip'\n",
    "\n",
    "# Zip XML, and the two JPGS\n",
    "dp_files = [xml_filename, thumbnail_filename, quicklook_filename]\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, \"w\") as f:\n",
    "    for name in dp_files:\n",
    "        f.write(name, os.path.basename(name), zipfile.ZIP_DEFLATED)\n",
    "    \n",
    "# Make sure it works OK\n",
    "def zip_count(f):\n",
    "    \"\"\"Given zip filename, returns number of files inside.\n",
    "    \n",
    "    str -> int\"\"\"\n",
    "    from contextlib import closing\n",
    "    with closing(zipfile.ZipFile(f)) as archive:\n",
    "        num_files = len(archive.infolist())\n",
    "    return num_files\n",
    "\n",
    "# Make sure only three files in zip\n",
    "assert zip_count(zip_filename) == 3\n",
    "# And total zip size is under 2 MB\n",
    "assert os.path.getsize(zip_filename) / 1024**2 < 2\n",
    "\n",
    "print('Zip file size: ', round(os.path.getsize(zip_filename) / 1024, 2), 'kB')\n",
    "print('Name:', zip_filename)\n",
    "print('Contains', zip_count(zip_filename), 'files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Upload to COS-2 API\n",
    "Upload to the COS-2 API can be done through the command line (also called \"shell\"), with the help of the program **cURL**. Instructions on how to install it on CSA Windows machines can be found in [Section 8](#cURL). Of note, for this Notebook we are sending this only to the test server. The production server's address is actually located here:\n",
    "\n",
    ">**OPERATIONAL Environment**\n",
    "\n",
    ">•\tagency =  CSA\n",
    "\n",
    ">•\thost = disasterscharter.org\n",
    "\n",
    ">•\tprotocol = https\n",
    "\n",
    ">•\tusername = MPP_CSA\n",
    "\n",
    ">•\tpassword =\t*\n",
    "\n",
    ">*the password is sent by the site operator. The script credentials are different from the EO-SSO account details used to access the web interface*. \n",
    "\n",
    "and invoked with the following:\n",
    "\n",
    "~~~bash\n",
    "curl -i -k -X POST --form product=\"@<product-file-path>\" --form public-data=<false/true> –basic https://<username>:<password>@<host>/charter-portlets/service/data-product/<agency>/<satellite>/<call-id>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "# Test environemnt\n",
    "username = 'mpp.csa'\n",
    "password = 'mpp.csa'\n",
    "test_server = 'https://charter.training.esaportal.eu/web/guest/home'\n",
    "invoke_str = 'curl -i -k -X POST --form product=\"@{0}\" --form public-data=TRUE –basic https://{1}:{2}@intlcharter-prod.netcetera.ch/charter-portlets/service/data-product/CSA/RADARSAT2/{1}'.format(zip_filename, activation_number)\n",
    "\n",
    "try:\n",
    "    subprocess.check_output(invoke_str)\n",
    "except subprocess.CalledProcessError as exc:                                                                                                   \n",
    "    print('Error code', exc.returncode, exc.output)\n",
    "\n",
    "# Commented out in Notebook for testing.\n",
    "# Delete the zip as we don't need it anymore\n",
    "# from glob import glob\n",
    "# os.remove(zip_filename)\n",
    "# assert len(glob('*.zip')) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion: Dealing with cURL error\n",
    "Well, that's a shame, and will need to be looked into further. In fact, when running the same command in `CMD.exe`, we get the **following result** back also:\n",
    "\n",
    "    curl: (6) Couldn't resolve host 'intlcharter-prod.netcetera.ch'\n",
    "\n",
    "\n",
    "The leading possibility is that COS-2's test server is no longer up and running. In this case, **testing** on our side would be needed on the the **actual production server instead**.\n",
    "\n",
    "The other is that the supplied adress had got a typo, or that I haven't copied it corretly in the code.\n",
    "\n",
    "In any case, the decent thing to do would be to **contact the COS-2 folks** to troubleshoot the issue, before attempting anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Notes on Dependencies\n",
    "### Anaconda\n",
    "This notebook was built using the latest (as of writing) [Anaconda3 distribution](https://www.continuum.io/downloads) from Continuum Analytics. It is free of charge and runs only for the local user, so can be installed without admin priviledges for Windows users. It is slowly becoming the standard distribution for scientific and engineering Python uses, as it:\n",
    "\n",
    "1. comes with many batteries included (scientific packages), and\n",
    "2. comes with its own package manager, *conda*, similar to pip, but ships binaries that are tested on all major platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cURL\n",
    "Taken from PR0541_A_COS-2_MPP_Manual_of_Operations.pdf:\n",
    "\n",
    ">7. REST SERVICES\n",
    "REST services provide a way to automate the upload of AAP or Metadata (with Products or links to\n",
    "the Products) without logging into COS-2. The system offers web services that can be invoked directly\n",
    "from the command line by using an HTTP tool such as cURL.\n",
    "7.1.1 Installing cURL on Windows\n",
    "\n",
    "<img src=\"img/curl.jpg\" width=\"400\">\n",
    "\n",
    ">Go to http://curl.haxx.se/download.html, and download the correct installation file for the OD/MPP\n",
    "Agency’s operating system (“Win64 – Generic” or “Win32 – Generic” for Windows).\n",
    "\n",
    "<img src=\"img/Adding_PATH_to_Windows.jpg\" width=\"400\">\n",
    "\n",
    ">Unzip the archive and add the location (should contain curl.exe) to the PATH system variable in order\n",
    "to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!curl --version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
